// GPT-4 Streaming Client for real-time conversation
// Streams responses token-by-token for low latency

const axios = require('axios');
const EventEmitter = require('events');

class GPT4StreamingClient extends EventEmitter {
  constructor(apiKey, systemPrompt = null) {
    super();
    this.apiKey = apiKey;
    this.baseUrl = 'https://api.openai.com/v1/chat/completions';
    this.conversationHistory = [];
    this.customerName = null; // ◊©◊ù ◊î◊ú◊ß◊ï◊ó
    this.systemPrompt = systemPrompt || this.getDefaultSalesPrompt();
  }

  /**
   * Default sales agent system prompt
   */
  getDefaultSalesPrompt() {
    return `◊ê◊™◊î ◊°◊ï◊õ◊ü ◊û◊õ◊ô◊®◊ï◊™ ◊ï◊™◊û◊ô◊õ◊™ ◊ú◊ß◊ï◊ó◊ï◊™ ◊û◊ß◊¶◊ï◊¢◊ô ◊ë◊¢◊ë◊®◊ô◊™, ◊©◊û◊ì◊ë◊® ◊ë◊ò◊ú◊§◊ï◊ü ◊¢◊ù ◊ú◊ß◊ï◊ó◊ï◊™.

üéØ **◊ê◊ô◊©◊ô◊ï◊™ ◊ï◊™◊§◊ß◊ô◊ì:**
- ◊ì◊ï◊ë◊® ◊¢◊ë◊®◊ô◊™ ◊©◊ï◊ò◊§◊™, ◊ó◊ë◊®◊ï◊™◊ô ◊ï◊û◊ß◊¶◊ï◊¢◊ô
- ◊ê◊ô◊© ◊û◊õ◊ô◊®◊ï◊™ ◊û◊†◊ï◊°◊î ◊©◊ô◊ï◊ì◊¢ ◊ú◊î◊ß◊©◊ô◊ë ◊ï◊ú◊ñ◊î◊ï◊™ ◊¶◊®◊õ◊ô◊ù
- ◊û◊†◊î◊ú ◊©◊ô◊ó◊î ◊ò◊ë◊¢◊ô◊™ ◊ï◊†◊¢◊ô◊û◊î, ◊ú◊ê ◊®◊ï◊ë◊ï◊ò◊ô◊™
- ◊™◊û◊ô◊ì ◊ó◊ô◊ï◊ë◊ô, ◊ê◊ï◊§◊ò◊ô◊û◊ô ◊ï◊¢◊ï◊ñ◊®

üí¨ **◊°◊í◊†◊ï◊ü ◊©◊ô◊ó◊î:**
- ◊™◊û◊ô◊ì ◊§◊™◊ó ◊ë◊©◊ô◊ó◊î: "◊î◊ô◊ô, ◊†◊¢◊ô◊ù ◊û◊ê◊ï◊ì! ◊û◊î ◊©◊ú◊ï◊û◊ö?"
- ◊©◊ê◊ú ◊ê◊™ ◊©◊ù ◊î◊ú◊ß◊ï◊ó ◊ë◊î◊™◊ó◊ú◊î ◊ï◊™◊©◊™◊û◊© ◊ë◊ï ◊ú◊ê◊ï◊®◊ö ◊î◊©◊ô◊ó◊î
- ◊ñ◊õ◊ï◊® ◊§◊®◊ò◊ô◊ù ◊ó◊©◊ï◊ë◊ô◊ù ◊©◊î◊ú◊ß◊ï◊ó ◊û◊°◊§◊® (◊©◊ù, ◊¶◊®◊õ◊ô◊ù, ◊î◊¢◊ì◊§◊ï◊™)
- ◊ì◊ë◊® ◊ë◊ê◊ï◊§◊ü ◊©◊ô◊ó◊™◊ô ◊ï◊ò◊ë◊¢◊ô, ◊ú◊ê ◊§◊ï◊®◊û◊ú◊ô ◊û◊ì◊ô
- ◊¢◊†◊î ◊ë◊ß◊¶◊®◊î (1-3 ◊û◊©◊§◊ò◊ô◊ù) - ◊ñ◊ï ◊©◊ô◊ó◊™ ◊ò◊ú◊§◊ï◊ü, ◊ú◊ê ◊û◊°◊û◊ö
- ◊ê◊ú ◊™◊©◊™◊û◊© ◊ë-"*", bullet points ◊ê◊ï ◊°◊ô◊û◊†◊ô◊ù ◊û◊ô◊ï◊ó◊ì◊ô◊ù - ◊®◊ß ◊ò◊ß◊°◊ò ◊®◊í◊ô◊ú

üß† **◊ô◊õ◊ï◊ú◊ï◊™:**
- ◊ñ◊ô◊î◊ï◊ô ◊¶◊®◊õ◊ô◊ù: ◊î◊ß◊©◊ë ◊û◊î ◊î◊ú◊ß◊ï◊ó ◊¶◊®◊ô◊ö ◊ï◊©◊ê◊ú ◊©◊ê◊ú◊ï◊™ ◊û◊ë◊®◊®◊ï◊™
- ◊ñ◊õ◊ï◊® ◊û◊ô◊ì◊¢: ◊ê◊ù ◊î◊ú◊ß◊ï◊ó ◊ê◊û◊® ◊ê◊™ ◊©◊û◊ï/◊§◊®◊ò◊ô◊ù - ◊ñ◊õ◊ï◊® ◊ï◊™◊©◊™◊û◊© ◊ë◊î◊ù
- ◊ò◊ô◊§◊ï◊ú ◊ë◊î◊™◊†◊í◊ì◊ï◊ô◊ï◊™: ◊ê◊ù ◊î◊ú◊ß◊ï◊ó ◊û◊î◊°◊° - ◊™◊ü ◊û◊¢◊†◊î ◊ó◊ô◊ï◊ë◊ô ◊ï◊¢◊†◊ô◊†◊ô
- ◊î◊†◊¢◊î ◊ú◊§◊¢◊ï◊ú◊î: ◊¢◊ï◊ì◊ì ◊ê◊™ ◊î◊ú◊ß◊ï◊ó ◊ú◊ß◊ë◊ï◊¢ ◊§◊í◊ô◊©◊î/◊ú◊î◊û◊©◊ô◊ö ◊ë◊™◊î◊ú◊ô◊ö

üìã **◊ì◊ï◊í◊û◊ê◊ï◊™ ◊ú◊©◊ô◊ó◊î:**
- "◊î◊ô◊ô ◊ì◊†◊ô! ◊©◊û◊ó◊™◊ô ◊ú◊ì◊ë◊® ◊ê◊ô◊™◊ö. ◊û◊î ◊î◊ì◊ë◊® ◊î◊¢◊ô◊ß◊®◊ô ◊©◊ê◊™◊î ◊û◊ó◊§◊©?"
- "◊û◊¢◊ï◊ú◊î! ◊ñ◊î ◊ë◊ì◊ô◊ï◊ß ◊û◊î ◊©◊ê◊†◊ó◊†◊ï ◊¢◊ï◊©◊ô◊ù. ◊°◊§◊® ◊ú◊ô ◊¢◊ï◊ì..."
- "◊†◊©◊û◊¢ ◊û◊¢◊†◊ô◊ô◊ü! ◊ë◊ï◊ê ◊†◊ß◊ë◊¢ ◊§◊í◊ô◊©◊î ◊ß◊¶◊®◊î ◊ú◊®◊ê◊ï◊™ ◊ê◊ô◊ö ◊ê◊§◊©◊® ◊ú◊¢◊ñ◊ï◊®?"

‚ùå **◊ê◊ú ◊™◊¢◊©◊î:**
- ◊ú◊ê ◊ú◊î◊©◊™◊û◊© ◊ë◊ê◊û◊ï◊í'◊ô ◊ë◊™◊©◊ï◊ë◊ï◊™ (◊ñ◊ï ◊©◊ô◊ó◊™ ◊ò◊ú◊§◊ï◊ü)
- ◊ú◊ê ◊ú◊õ◊™◊ï◊ë ◊®◊©◊ô◊û◊ï◊™ ◊¢◊ù ◊û◊ß◊§◊ô◊ù ◊ê◊ï ◊õ◊ï◊õ◊ë◊ô◊ï◊™
- ◊ú◊ê ◊ú◊î◊ô◊ï◊™ ◊ô◊ë◊© ◊ê◊ï ◊§◊ï◊®◊û◊ú◊ô ◊û◊ì◊ô
- ◊ú◊ê ◊ú◊™◊™ ◊™◊©◊ï◊ë◊ï◊™ ◊ê◊®◊ï◊õ◊ï◊™ (◊û◊ß◊° 3 ◊û◊©◊§◊ò◊ô◊ù)

◊ñ◊õ◊ï◊®: ◊ê◊™◊î ◊û◊ì◊ë◊® ◊¢◊ù ◊ê◊†◊©◊ô◊ù ◊ê◊û◊ô◊™◊ô◊ô◊ù ◊ë◊ò◊ú◊§◊ï◊ü. ◊™◊î◊ô◊î ◊ò◊ë◊¢◊ô, ◊ó◊ë◊®◊ï◊™◊ô ◊ï◊ê◊†◊ï◊©◊ô!`;
  }

  /**
   * Set custom system prompt
   */
  setSystemPrompt(prompt) {
    this.systemPrompt = prompt;
  }

  /**
   * Get conversation history
   */
  getHistory() {
    return this.conversationHistory;
  }

  /**
   * Clear conversation history
   */
  clearHistory() {
    this.conversationHistory = [];
  }

  /**
   * Add user message to history
   */
  addUserMessage(text) {
    this.conversationHistory.push({
      role: 'user',
      content: text
    });
  }

  /**
   * Add assistant message to history
   */
  addAssistantMessage(text) {
    this.conversationHistory.push({
      role: 'assistant',
      content: text
    });
  }

  /**
   * Generate streaming response
   * Emits 'token' events for each token
   * Emits 'complete' event with full text when done
   */
  async generateResponse(userMessage) {
    // Add user message to history
    this.addUserMessage(userMessage);

    // Build messages array
    const messages = [
      { role: 'system', content: this.systemPrompt },
      ...this.conversationHistory
    ];

    console.log(`ü§ñ Generating GPT-4 response for: "${userMessage}"`);

    try {
      const response = await axios.post(
        this.baseUrl,
        {
          model: 'gpt-4o', // Fast, high-quality
          messages: messages,
          temperature: 0.7,
          max_tokens: 150, // Keep responses short for voice
          stream: true
        },
        {
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json'
          },
          responseType: 'stream',
          timeout: 30000
        }
      );

      let fullText = '';

      // Process stream
      return new Promise((resolve, reject) => {
        response.data.on('data', (chunk) => {
          const lines = chunk.toString().split('\n').filter(line => line.trim() !== '');

          for (const line of lines) {
            if (line.includes('[DONE]')) {
              // Stream complete
              console.log(`‚úÖ GPT-4 response complete: "${fullText}"`);
              this.addAssistantMessage(fullText);
              this.emit('complete', fullText);
              resolve(fullText);
              return;
            }

            if (line.startsWith('data: ')) {
              try {
                const json = JSON.parse(line.substring(6));
                const delta = json.choices?.[0]?.delta?.content;

                if (delta) {
                  fullText += delta;
                  this.emit('token', delta);
                }
              } catch (error) {
                // Ignore parsing errors for non-JSON lines
              }
            }
          }
        });

        response.data.on('error', (error) => {
          console.error('‚ùå GPT-4 stream error:', error);
          this.emit('error', error);
          reject(error);
        });

        response.data.on('end', () => {
          if (fullText) {
            console.log(`‚úÖ GPT-4 response complete: "${fullText}"`);
            this.addAssistantMessage(fullText);
            this.emit('complete', fullText);
            resolve(fullText);
          }
        });
      });
    } catch (error) {
      console.error('‚ùå GPT-4 error:', error.message);
      if (error.response) {
        console.error('   Status:', error.response.status);
        console.error('   Data:', error.response.data);
      }
      this.emit('error', error);
      throw error;
    }
  }

  /**
   * Generate non-streaming response (simpler, but higher latency)
   */
  async generateResponseSync(userMessage) {
    this.addUserMessage(userMessage);

    const messages = [
      { role: 'system', content: this.systemPrompt },
      ...this.conversationHistory
    ];

    try {
      const response = await axios.post(
        this.baseUrl,
        {
          model: 'gpt-4o',
          messages: messages,
          temperature: 0.7,
          max_tokens: 150
        },
        {
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json'
          },
          timeout: 30000
        }
      );

      const text = response.data.choices[0].message.content;
      console.log(`ü§ñ GPT-4 response: "${text}"`);
      this.addAssistantMessage(text);

      return text;
    } catch (error) {
      console.error('‚ùå GPT-4 error:', error.message);
      throw error;
    }
  }
}

module.exports = GPT4StreamingClient;
