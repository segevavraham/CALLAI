// Twilio Media Streams <-> n8n WebSocket Bridge - OPTIMIZED FOR REAL-TIME
const express = require('express');
const WebSocket = require('ws');
const axios = require('axios');
const { spawn } = require('child_process');
const fs = require('fs').promises;
const path = require('path');

const app = express();
const PORT = process.env.PORT || 3000;

// ‚öôÔ∏è ◊î◊í◊ì◊®◊ï◊™ - OPTIMIZED FOR REAL-TIME CONVERSATION
const N8N_WEBHOOK_URL = process.env.N8N_WEBHOOK_URL || 'https://segevavraham.app.n8n.cloud/webhook/twilio-process-audio';
const SILENCE_TIMEOUT = 600; // 600ms - ultra-fast response ‚ö°‚ö°
const MIN_AUDIO_CHUNKS = 8; // Very low threshold - prioritize speed üé§
const CHUNK_SIZE = 160; // Twilio standard
const MAX_IDLE_TIME = 30000; // 30 seconds of silence before timeout warning
const CONVERSATION_TIMEOUT = 300000; // 5 minutes total conversation limit
const MAX_HISTORY_MESSAGES = 50; // Maximum messages to keep in history (prevent memory issues)

// üìä Performance tracking
let performanceStats = {
  totalCalls: 0,
  averageProcessingTime: 0,
  averageN8nTime: 0,
  averageConversionTime: 0
};

// ◊ê◊ó◊°◊ï◊ü ◊ñ◊û◊†◊ô ◊©◊ú ◊ó◊ô◊ë◊ï◊®◊ô WebSocket ◊§◊¢◊ô◊ú◊ô◊ù
const activeCalls = new Map();

// üè• Health check endpoint
app.get('/health', (req, res) => {
  res.json({
    status: 'healthy',
    uptime: process.uptime(),
    activeCalls: activeCalls.size,
    timestamp: new Date().toISOString(),
    config: {
      silenceTimeout: SILENCE_TIMEOUT,
      minAudioChunks: MIN_AUDIO_CHUNKS,
      maxIdleTime: MAX_IDLE_TIME,
      maxHistoryMessages: MAX_HISTORY_MESSAGES
    }
  });
});

// üìä Stats endpoint
app.get('/stats', (req, res) => {
  const stats = {
    activeCalls: activeCalls.size,
    performance: {
      totalProcessedCalls: performanceStats.totalCalls,
      averageN8nTime: Math.round(performanceStats.averageN8nTime),
      averageProcessingTime: Math.round(performanceStats.averageProcessingTime),
      averageConversionTime: Math.round(performanceStats.averageConversionTime)
    },
    calls: []
  };

  activeCalls.forEach((callData, callSid) => {
    stats.calls.push({
      callSid,
      duration: Math.round((Date.now() - callData.startTime) / 1000),
      turns: callData.turnCount,
      historySize: callData.conversationHistory.length,
      isProcessing: callData.isProcessing,
      isSpeaking: callData.currentAudioPlaying
    });
  });

  res.json(stats);
});

// Express endpoint ◊ú-TwiML ◊©◊ú Twilio
app.get('/voice', (req, res) => {
  const wsUrl = `wss://${req.get('host')}/media-stream`;

  const twiml = `<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Connect>
        <Stream url="${wsUrl}" />
    </Connect>
</Response>`;

  res.type('text/xml');
  res.send(twiml);
});

// ◊î◊§◊¢◊ú HTTP server
const server = app.listen(PORT, () => {
  console.log(`üöÄ Server running on port ${PORT}`);
  console.log(`üéØ Twilio-n8n WebSocket Bridge - ENTERPRISE QUALITY`);
  console.log(`\nüìã Configuration:`);
  console.log(`   ‚ö° Silence timeout: ${SILENCE_TIMEOUT}ms`);
  console.log(`   üé§ Min audio chunks: ${MIN_AUDIO_CHUNKS}`);
  console.log(`   ‚è±Ô∏è  Max idle time: ${MAX_IDLE_TIME / 1000}s`);
  console.log(`   üîÑ Conversation timeout: ${CONVERSATION_TIMEOUT / 1000}s`);
  console.log(`\n‚úÖ Features:`);
  console.log(`   üìö Full conversation history tracking`);
  console.log(`   üö® Automatic error recovery`);
  console.log(`   ‚è±Ô∏è  Intelligent timeout management`);
  console.log(`   üìä Detailed call analytics\n`);
});

// ◊î◊§◊¢◊ú WebSocket server
const wss = new WebSocket.Server({ server, path: '/media-stream' });

wss.on('connection', (ws) => {
  console.log('üìû New Twilio call connected');

  let callSid = null;
  let streamSid = null;
  let welcomeSent = false;

  ws.on('message', async (message) => {
    try {
      const msg = JSON.parse(message);

      switch (msg.event) {
        case 'start':
          callSid = msg.start.callSid;
          streamSid = msg.start.streamSid;
          console.log(`üìû Call started: ${callSid}`);
          activeCalls.set(callSid, {
            ws,
            streamSid,
            audioBuffer: [],
            isProcessing: false,
            currentAudioPlaying: false,  // ‚úÖ Track AI speaking state
            conversationHistory: [],     // üìö Full conversation context
            startTime: Date.now(),       // ‚è±Ô∏è  Track call duration
            lastActivityTime: Date.now(), // üëÇ Track user activity
            turnCount: 0,                // üî¢ Track conversation turns
            idleWarningsSent: 0,         // ‚ö†Ô∏è  Track timeout warnings
            silenceTimeout: null         // üé§ VAD timeout reference
          });
          
          // ‚è±Ô∏è  ◊î◊§◊¢◊ú ◊†◊ô◊î◊ï◊ú timeout
          setupIdleTimeout(callSid);

          // ◊©◊ú◊ó ◊î◊ï◊ì◊¢◊™ ◊§◊™◊ô◊ó◊î ◊ë◊¢◊ë◊®◊ô◊™ ◊û◊ô◊ì!
          if (!welcomeSent) {
            welcomeSent = true;
            console.log('üëã Sending welcome message in 300ms...');
            setTimeout(() => {
              sendWelcomeMessage(callSid, streamSid, ws);
            }, 300);
          }
          break;

        case 'media':
          // ◊ê◊ù AI ◊û◊ì◊ë◊® - ignore user audio (prevent interruption feedback loop)
          const callData = activeCalls.get(callSid);
          if (!callData) {
            console.warn(`‚ö†Ô∏è  No call data for ${callSid}`);
            break;
          }

          // Debug logging - only log every 50 chunks to avoid spam
          if (callData.audioBuffer.length % 50 === 0 && callData.audioBuffer.length > 0) {
            console.log(`üìä Audio buffer: ${callData.audioBuffer.length} chunks | Processing: ${callData.isProcessing} | Speaking: ${callData.currentAudioPlaying}`);
          }

          if (callData.currentAudioPlaying) {
            // AI is speaking, ignore user input to prevent feedback
            break;
          }

          // ‚úÖ Use callData.audioBuffer
          callData.audioBuffer.push(msg.media.payload);

          // ‚ö° Real-time VAD - use callData.silenceTimeout
          if (callData.silenceTimeout) {
            clearTimeout(callData.silenceTimeout);
          }

          callData.silenceTimeout = setTimeout(async () => {
            const currentCallData = activeCalls.get(callSid);
            if (!currentCallData) return;

            // Only process if we have enough audio AND not currently processing
            if (currentCallData.audioBuffer.length >= MIN_AUDIO_CHUNKS && !currentCallData.isProcessing) {
              currentCallData.isProcessing = true;
              const chunksToProcess = [...currentCallData.audioBuffer];
              currentCallData.audioBuffer = []; // ‚úÖ Clear buffer for next turn

              console.log(`\nüé§ Processing ${chunksToProcess.length} audio chunks (Turn ${currentCallData.turnCount + 1})`);
              await processAudio(callSid, streamSid, chunksToProcess, ws);
              // Note: processAudio will reset isProcessing flag when done
            } else if (currentCallData.audioBuffer.length < MIN_AUDIO_CHUNKS) {
              console.log(`‚è≠Ô∏è  Skipping - only ${currentCallData.audioBuffer.length} chunks (need ${MIN_AUDIO_CHUNKS})`);
              currentCallData.audioBuffer = [];
            } else if (currentCallData.isProcessing) {
              console.log(`‚è∏Ô∏è  Already processing, buffering ${currentCallData.audioBuffer.length} chunks`);
            }
          }, SILENCE_TIMEOUT);
          break;

        case 'stop':
          console.log(`üìû Call ended: ${callSid}`);
          const endCallData = activeCalls.get(callSid);
          if (endCallData) {
            // ◊†◊ß◊î ◊ê◊™ ◊õ◊ú ◊î-timeouts
            if (endCallData.idleTimeout) clearTimeout(endCallData.idleTimeout);
            if (endCallData.silenceTimeout) clearTimeout(endCallData.silenceTimeout);

            // üìä ◊ú◊ï◊í ◊°◊ò◊ò◊ô◊°◊ò◊ô◊ß◊ï◊™ ◊©◊ô◊ó◊î
            const callDuration = Date.now() - endCallData.startTime;
            console.log(`üìä Call Stats:`);
            console.log(`   ‚è±Ô∏è  Duration: ${Math.round(callDuration / 1000)}s`);
            console.log(`   üî¢ Turns: ${endCallData.turnCount}`);
            console.log(`   üìö Messages: ${endCallData.conversationHistory.length}`);
          }
          activeCalls.delete(callSid);
          break;
      }
    } catch (error) {
      console.error('‚ùå Error processing message:', error);
    }
  });

  ws.on('close', () => {
    console.log('üìû WebSocket connection closed');
    if (callSid) {
      const closeCallData = activeCalls.get(callSid);
      if (closeCallData) {
        if (closeCallData.idleTimeout) clearTimeout(closeCallData.idleTimeout);
        if (closeCallData.silenceTimeout) clearTimeout(closeCallData.silenceTimeout);
      }
      activeCalls.delete(callSid);
    }
  });
});

// üéµ ◊§◊ï◊†◊ß◊¶◊ô◊î ◊ú◊î◊û◊ô◊® MP3 ◊ú-mulaw ◊ë◊ê◊û◊¶◊¢◊ï◊™ ffmpeg
async function convertMp3ToMulaw(mp3Base64) {
  const tempDir = '/tmp';
  const timestamp = Date.now();
  const mp3Path = path.join(tempDir, `audio_${timestamp}.mp3`);
  const mulawPath = path.join(tempDir, `audio_${timestamp}.ulaw`);

  try {
    // ◊õ◊™◊ï◊ë MP3 ◊ú◊ß◊ï◊ë◊• ◊ñ◊û◊†◊ô
    const mp3Buffer = Buffer.from(mp3Base64, 'base64');
    await fs.writeFile(mp3Path, mp3Buffer);

    // ◊î◊û◊® ◊ë◊ê◊û◊¶◊¢◊ï◊™ ffmpeg
    await new Promise((resolve, reject) => {
      const ffmpeg = spawn('ffmpeg', [
        '-i', mp3Path,
        '-ar', '8000',      // 8kHz sample rate (Twilio requirement)
        '-ac', '1',         // mono
        '-f', 'mulaw',      // output format
        mulawPath,
        '-y'                // overwrite output file
      ]);

      let stderr = '';
      ffmpeg.stderr.on('data', (data) => {
        stderr += data.toString();
      });

      ffmpeg.on('close', (code) => {
        if (code === 0) {
          resolve();
        } else {
          console.error('‚ùå ffmpeg error:', stderr);
          reject(new Error(`ffmpeg exited with code ${code}`));
        }
      });

      ffmpeg.on('error', (err) => {
        reject(err);
      });
    });

    // ◊ß◊®◊ê ◊ê◊™ ◊ß◊ï◊ë◊• ◊î-mulaw
    const mulawBuffer = await fs.readFile(mulawPath);
    const mulawBase64 = mulawBuffer.toString('base64');
    
    console.log('‚úÖ Converted:', {
      mp3: mp3Buffer.length,
      mulaw: mulawBuffer.length
    });

    // ◊†◊ß◊î ◊ß◊ë◊¶◊ô◊ù ◊ñ◊û◊†◊ô◊ô◊ù
    await fs.unlink(mp3Path).catch(() => {});
    await fs.unlink(mulawPath).catch(() => {});

    return mulawBase64;
  } catch (error) {
    console.error('‚ùå Conversion error:', error.message);
    
    await fs.unlink(mp3Path).catch(() => {});
    await fs.unlink(mulawPath).catch(() => {});
    
    throw error;
  }
}

// üìö ◊§◊ï◊†◊ß◊¶◊ô◊î ◊ú◊†◊ô◊î◊ï◊ú ◊í◊ï◊ì◊ú ◊î◊ô◊°◊ò◊ï◊®◊ô◊î (◊ú◊û◊†◊ï◊¢ ◊ë◊¢◊ô◊ï◊™ ◊ñ◊ô◊õ◊®◊ï◊ü)
function manageHistorySize(callData) {
  if (callData.conversationHistory.length > MAX_HISTORY_MESSAGES) {
    // ◊©◊û◊ï◊® ◊®◊ß ◊ê◊™ ◊î◊î◊ï◊ì◊¢◊ï◊™ ◊î◊ê◊ó◊®◊ï◊†◊ï◊™, ◊ê◊ë◊ú ◊™◊û◊ô◊ì ◊©◊û◊ï◊® ◊ê◊™ ◊î◊ï◊ì◊¢◊™ ◊î◊§◊™◊ô◊ó◊î
    const welcomeMessage = callData.conversationHistory.find(msg => msg.type === 'welcome');
    const recentMessages = callData.conversationHistory.slice(-MAX_HISTORY_MESSAGES + 1);

    if (welcomeMessage && !recentMessages.some(msg => msg.type === 'welcome')) {
      callData.conversationHistory = [welcomeMessage, ...recentMessages];
    } else {
      callData.conversationHistory = recentMessages;
    }

    console.log(`üìö History trimmed to ${callData.conversationHistory.length} messages`);
  }
}

// üö® ◊§◊ï◊†◊ß◊¶◊ô◊î ◊ú◊©◊ú◊ô◊ó◊™ ◊î◊ï◊ì◊¢◊™ ◊©◊í◊ô◊ê◊î
async function sendErrorMessage(callSid, streamSid, ws, errorType = 'general') {
  try {
    console.log(`‚ö†Ô∏è  Sending error recovery message for ${callSid}`);

    const errorMessages = {
      general: '◊°◊ú◊ô◊ó◊î, ◊†◊™◊ß◊ú◊™◊ô ◊ë◊ë◊¢◊ô◊î ◊ò◊õ◊†◊ô◊™. ◊ê◊§◊©◊® ◊ú◊ó◊ñ◊ï◊® ◊¢◊ú ◊û◊î ◊©◊ê◊û◊®◊™?',
      timeout: '◊°◊ú◊ô◊ó◊î, ◊ú◊ê ◊©◊û◊¢◊™◊ô ◊ê◊ï◊™◊ö. ◊ê◊™◊î ◊¢◊ì◊ô◊ô◊ü ◊ê◊ô◊™◊ô?',
      n8n_error: '◊°◊ú◊ô◊ó◊î, ◊ô◊© ◊ú◊ô ◊ë◊¢◊ô◊î ◊ñ◊û◊†◊ô◊™. ◊†◊°◊î ◊©◊ï◊ë ◊ë◊ë◊ß◊©◊î.'
    };

    const payload = {
      callSid,
      streamSid,
      audioData: 'AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA',
      errorRecovery: true,
      errorType,
      errorMessage: errorMessages[errorType] || errorMessages.general
    };

    const response = await axios.post(N8N_WEBHOOK_URL, payload, {
      timeout: 15000,
      headers: { 'Content-Type': 'application/json' }
    });

    if (response.data.success && response.data.audio) {
      let audioPayload = response.data.audio;

      if (response.data.format === 'mp3') {
        audioPayload = await convertMp3ToMulaw(audioPayload);
      }

      await sendAudioToTwilio(ws, streamSid, audioPayload);
      console.log('‚úÖ Error recovery message sent');
    }
  } catch (error) {
    console.error('‚ùå Failed to send error message:', error.message);
    // ◊ê◊ù ◊í◊ù ◊î◊ï◊ì◊¢◊™ ◊î◊©◊í◊ô◊ê◊î ◊†◊õ◊©◊ú◊î, ◊§◊©◊ï◊ò ◊†◊û◊©◊ô◊ö
  }
}

// ‚è±Ô∏è  ◊§◊ï◊†◊ß◊¶◊ô◊î ◊ú◊†◊ô◊î◊ï◊ú timeouts
function setupIdleTimeout(callSid) {
  const callData = activeCalls.get(callSid);
  if (!callData) return;

  // ◊†◊ß◊î timeout ◊ß◊ï◊ì◊ù ◊ê◊ù ◊ß◊ô◊ô◊ù
  if (callData.idleTimeout) {
    clearTimeout(callData.idleTimeout);
  }

  callData.idleTimeout = setTimeout(async () => {
    const timeSinceLastActivity = Date.now() - callData.lastActivityTime;

    if (timeSinceLastActivity >= MAX_IDLE_TIME && callData.idleWarningsSent < 2) {
      console.log(`‚ö†Ô∏è  User idle for ${timeSinceLastActivity}ms on call ${callSid}`);
      callData.idleWarningsSent++;
      await sendErrorMessage(callSid, callData.streamSid, callData.ws, 'timeout');

      // ◊î◊í◊ì◊® timeout ◊†◊ï◊°◊£
      setupIdleTimeout(callSid);
    } else if (callData.idleWarningsSent >= 2) {
      console.log(`üìû Ending call ${callSid} due to inactivity`);
      callData.ws.close();
    }
  }, MAX_IDLE_TIME);
}

// ◊§◊ï◊†◊ß◊¶◊ô◊î ◊ú◊©◊ú◊ô◊ó◊™ ◊î◊ï◊ì◊¢◊™ ◊§◊™◊ô◊ó◊î
async function sendWelcomeMessage(callSid, streamSid, ws) {
  try {
    console.log('üí¨ Generating Hebrew welcome message via n8n');
    
    const silenceBase64 = 'AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA';
    
    const payload = {
      callSid,
      streamSid,
      audioData: silenceBase64,
      welcomeMessage: true
    };
    
    const response = await axios.post(N8N_WEBHOOK_URL, payload, {
      timeout: 30000,
      headers: {
        'Content-Type': 'application/json'
      }
    });

    if (response.data.success && response.data.audio) {
      let audioPayload = response.data.audio;

      // ◊î◊û◊® MP3 ◊ú-mulaw
      if (response.data.format === 'mp3') {
        console.log('üîÑ Converting welcome MP3 to mulaw...');
        audioPayload = await convertMp3ToMulaw(audioPayload);
      }

      console.log('üîä Playing welcome message');
      await sendAudioToTwilio(ws, streamSid, audioPayload);

      // üìö ◊î◊ï◊°◊£ ◊ú◊î◊ô◊°◊ò◊ï◊®◊ô◊ô◊™ ◊î◊©◊ô◊ó◊î
      const callData = activeCalls.get(callSid);
      if (callData && response.data.text) {
        callData.conversationHistory.push({
          role: 'assistant',
          content: response.data.text,
          timestamp: Date.now(),
          type: 'welcome'
        });
        callData.turnCount++;
      }

      console.log('‚úÖ Welcome message complete');
    }
  } catch (error) {
    console.error('‚ùå Error sending welcome:', error.message);
  }
}

async function processAudio(callSid, streamSid, audioChunks, ws) {
  const timings = {
    start: Date.now(),
    preparePayload: 0,
    n8nRequest: 0,
    n8nResponse: 0,
    conversion: 0,
    sendToTwilio: 0,
    updateHistory: 0,
    total: 0
  };

  const callData = activeCalls.get(callSid);

  if (!callData) {
    console.error(`‚ùå No call data found for ${callSid}`);
    return;
  }

  try {
    const audioBase64 = audioChunks.join('');

    // üëÇ ◊¢◊ì◊õ◊ü ◊ñ◊û◊ü ◊§◊¢◊ô◊ú◊ï◊™ ◊ê◊ó◊®◊ï◊ü
    callData.lastActivityTime = Date.now();

    // üìä ◊ú◊ï◊í ◊û◊§◊ï◊®◊ò ◊©◊ú ◊û◊¶◊ë ◊î◊©◊ô◊ó◊î
    const callDuration = Date.now() - callData.startTime;
    console.log(`\nüé§ Processing audio for ${callSid}`);
    console.log(`   üì¶ Chunks: ${audioChunks.length}`);
    console.log(`   üî¢ Turn: ${callData.turnCount + 1}`);
    console.log(`   ‚è±Ô∏è  Duration: ${Math.round(callDuration / 1000)}s`);
    console.log(`   üìö History: ${callData.conversationHistory.length} messages`);
    console.log(`   üîß Initial state: isProcessing=${callData.isProcessing}, speaking=${callData.currentAudioPlaying}`);

    // üîÑ ◊î◊õ◊ü payload ◊¢◊ù ◊î◊ô◊°◊ò◊ï◊®◊ô◊î ◊û◊ú◊ê◊î
    const payload = {
      callSid,
      streamSid,
      audioData: audioBase64,
      conversationHistory: callData.conversationHistory, // üìö CRITICAL: ◊©◊ú◊ó ◊ê◊™ ◊õ◊ú ◊î◊î◊ô◊°◊ò◊ï◊®◊ô◊î!
      metadata: {
        turnCount: callData.turnCount,
        callDuration: callDuration,
        timestamp: Date.now()
      }
    };

    timings.preparePayload = Date.now() - timings.start;

    // ‚è±Ô∏è Track n8n request time
    const n8nStartTime = Date.now();
    const response = await axios.post(N8N_WEBHOOK_URL, payload, {
      timeout: 30000,
      headers: { 'Content-Type': 'application/json' }
    });

    timings.n8nResponse = Date.now() - n8nStartTime;
    console.log(`üì• n8n responded in ${timings.n8nResponse}ms`);

    if (response.data.success && response.data.audio) {
      let audioPayload = response.data.audio;

      // ◊î◊û◊® MP3 ◊ú-mulaw
      if (response.data.format === 'mp3') {
        const convertStart = Date.now();
        console.log('üîÑ Converting response MP3 to mulaw...');
        audioPayload = await convertMp3ToMulaw(audioPayload);
        timings.conversion = Date.now() - convertStart;
        console.log(`‚úÖ Converted in ${timings.conversion}ms`);
      }

      const sendStart = Date.now();
      try {
        // ‚úÖ Mark that AI is speaking JUST before sending
        callData.currentAudioPlaying = true;

        await sendAudioToTwilio(ws, streamSid, audioPayload);
        timings.sendToTwilio = Date.now() - sendStart;

        // ‚úÖ IMMEDIATELY mark that AI stopped speaking
        callData.currentAudioPlaying = false;
        console.log(`üîä Audio sent successfully in ${timings.sendToTwilio}ms`);
      } catch (audioError) {
        console.error('‚ùå Error sending audio to Twilio:', audioError.message);
        timings.sendToTwilio = Date.now() - sendStart;
        callData.currentAudioPlaying = false;
        // Continue anyway - we'll reset flags below
      }

      const historyStart = Date.now();

      // üìö ◊¢◊ì◊õ◊ü ◊î◊ô◊°◊ò◊ï◊®◊ô◊ô◊™ ◊©◊ô◊ó◊î ◊¢◊ù ◊©◊†◊ô ◊î◊¶◊ì◊ì◊ô◊ù
      if (response.data.userText) {
        callData.conversationHistory.push({
          role: 'user',
          content: response.data.userText,
          timestamp: Date.now(),
          audioChunks: audioChunks.length
        });
      }

      if (response.data.text) {
        callData.conversationHistory.push({
          role: 'assistant',
          content: response.data.text,
          timestamp: Date.now(),
          processingTime: timings.n8nResponse
        });
      }

      // üìö ◊†◊î◊ú ◊í◊ï◊ì◊ú ◊î◊ô◊°◊ò◊ï◊®◊ô◊î
      manageHistorySize(callData);

      // üî¢ ◊¢◊ì◊õ◊ü ◊û◊ï◊†◊î ◊™◊ï◊®◊ï◊™
      callData.turnCount++;

      timings.updateHistory = Date.now() - historyStart;

      // ‚è±Ô∏è  ◊ê◊ô◊§◊ï◊° timeout - ◊ô◊© ◊§◊¢◊ô◊ú◊ï◊™
      setupIdleTimeout(callSid);

      // ‚úÖ Mark that processing is done - ready for next user input!
      callData.isProcessing = false; // ‚úÖ Critical: ready to process next input
      // Note: currentAudioPlaying already reset in sendAudioToTwilio block above

      timings.total = Date.now() - timings.start;

      // üìä Detailed timing breakdown
      console.log(`\n‚è±Ô∏è  TIMING BREAKDOWN:`);
      console.log(`   üì¶ Prepare payload: ${timings.preparePayload}ms`);
      console.log(`   üåê n8n processing: ${timings.n8nResponse}ms ‚ö†Ô∏è${timings.n8nResponse > 3000 ? ' SLOW!' : ''}`);
      console.log(`   üîÑ Audio conversion: ${timings.conversion}ms`);
      console.log(`   üì§ Send to Twilio: ${timings.sendToTwilio}ms`);
      console.log(`   üìö Update history: ${timings.updateHistory}ms`);
      console.log(`   ‚úÖ TOTAL: ${timings.total}ms\n`);

      // Update performance stats
      performanceStats.totalCalls++;
      performanceStats.averageN8nTime =
        (performanceStats.averageN8nTime * (performanceStats.totalCalls - 1) + timings.n8nResponse) / performanceStats.totalCalls;
      performanceStats.averageProcessingTime =
        (performanceStats.averageProcessingTime * (performanceStats.totalCalls - 1) + timings.total) / performanceStats.totalCalls;
      performanceStats.averageConversionTime =
        (performanceStats.averageConversionTime * (performanceStats.totalCalls - 1) + timings.conversion) / performanceStats.totalCalls;

      console.log(`üìö History now: ${callData.conversationHistory.length} messages`);
      console.log(`üîß State: isProcessing=${callData.isProcessing}, currentAudioPlaying=${callData.currentAudioPlaying}, bufferSize=${callData.audioBuffer.length}`);
      console.log('üëÇ Listening for next user input...\n');
    } else {
      console.error('‚ö†Ô∏è  Invalid response from n8n');

      // Reset flags so we can process next input
      callData.isProcessing = false;
      callData.currentAudioPlaying = false; // Just in case

      await sendErrorMessage(callSid, streamSid, ws, 'n8n_error');
    }
  } catch (error) {
    console.error('‚ùå Error processing audio:', error.message);
    if (error.response) {
      console.error('   Status:', error.response.status);
      console.error('   Data:', JSON.stringify(error.response.data, null, 2));
    }

    // üö® ◊©◊ú◊ó ◊î◊ï◊ì◊¢◊™ ◊©◊í◊ô◊ê◊î ◊ú◊û◊©◊™◊û◊©
    try {
      await sendErrorMessage(callSid, streamSid, ws, 'general');
    } catch (recoveryError) {
      console.error('‚ùå Failed to recover from error:', recoveryError.message);
    }

    // ‚úÖ Make sure we can process again even if there was an error
    if (callData) {
      callData.currentAudioPlaying = false;
      callData.isProcessing = false;

      // üìö ◊®◊©◊ï◊ù ◊©◊í◊ô◊ê◊î ◊ë◊î◊ô◊°◊ò◊ï◊®◊ô◊î
      callData.conversationHistory.push({
        role: 'system',
        content: 'Error occurred during processing',
        timestamp: Date.now(),
        error: error.message
      });
    }
  }
}

// Helper function to send audio to Twilio
async function sendAudioToTwilio(ws, streamSid, audioBase64) {
  const chunks = Math.ceil(audioBase64.length / CHUNK_SIZE);
  console.log(`üì§ Sending ${chunks} audio chunks to Twilio`);
  
  for (let i = 0; i < audioBase64.length; i += CHUNK_SIZE) {
    const chunk = audioBase64.substr(i, CHUNK_SIZE);
    
    ws.send(JSON.stringify({
      event: 'media',
      streamSid: streamSid,
      media: {
        payload: chunk
      }
    }));
    
    // Small delay between chunks to avoid overwhelming Twilio
    if (i % (CHUNK_SIZE * 10) === 0) {
      await new Promise(resolve => setTimeout(resolve, 10));
    }
  }
}
